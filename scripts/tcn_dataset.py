# -*- coding: utf-8 -*-
# scripts/tcn_dataset.py
"""
PyTorch Dataset class for fall detection sequences
- Reads CSV generated by generate_sequences.py
- Reshapes [seq_len*feat_dim] → [feat_dim, seq_len] for TCN
- Supports class weights calculation for imbalanced data
"""
import re
import pandas as pd
import torch
import numpy as np
from torch.utils.data import Dataset

class SequenceCSVDataset(Dataset):
    def __init__(self, csv_path):
        """
        Args:
            csv_path: Path to sequences CSV (train/val/test)
        """
        self.df = pd.read_csv(csv_path)

        # faqat f0, f1, f2, ... ustunlarini oling (feat_dim kabi boshqa 'f...' larni emas)
        feat_cols = [c for c in self.df.columns if re.fullmatch(r"f\d+", c)]
        if not feat_cols:
            raise ValueError("Feature ustunlar topilmadi (f0, f1, ...). CSV formatini tekshiring.")
        feat_cols = sorted(feat_cols, key=lambda x: int(x[1:]))  # f0,f1,...

        self.feat_cols = feat_cols
        self.X = self.df[self.feat_cols].values.astype("float32")

        # label_id ustuni bo'lishi kerak (0=no_fall,1=pre_fall,2=fall)
        if "label_id" not in self.df.columns:
            raise ValueError("CSVda 'label_id' ustuni yo'q. generate_sequences.py chiqishini tekshiring.")
        self.y = self.df["label_id"].values.astype("int64")

        # seq_len/feat_dim ni CSVdan olish (har qatorda bir xil bo'lishi kerak)
        if "seq_len" not in self.df.columns or "feat_dim" not in self.df.columns:
            raise ValueError("CSVda 'seq_len' va 'feat_dim' ustunlari bo'lishi shart.")

        self.seq_len = int(self.df["seq_len"].iloc[0])
        self.feat_dim = int(self.df["feat_dim"].iloc[0])

        # xavfsizlik: f-ustunlar soni seq_len*feat_dim ga tengligini tekshiring
        expected = self.seq_len * self.feat_dim
        if len(self.feat_cols) != expected:
            raise ValueError(
                f"Feature ustunlar soni mos emas: {len(self.feat_cols)} != seq_len*feat_dim ({expected}). "
                "generate_sequences.py parametrlarini tekshiring."
            )
        
        # Class distribution
        self._compute_class_info()

    def _compute_class_info(self):
        """Class counts va weights ni hisoblash"""
        unique, counts = np.unique(self.y, return_counts=True)
        self.class_counts = dict(zip(unique, counts))
        
        # Class weights (inverse frequency)
        total = len(self.y)
        self.class_weights = {}
        for cls, cnt in self.class_counts.items():
            self.class_weights[cls] = total / (len(self.class_counts) * cnt)
        
        # Tensor format (CrossEntropyLoss uchun)
        max_cls = max(self.class_counts.keys())
        weight_tensor = torch.zeros(max_cls + 1)
        for cls, weight in self.class_weights.items():
            weight_tensor[cls] = weight
        self.class_weight_tensor = weight_tensor

    def get_class_weights(self):
        """
        Returns:
            torch.Tensor: Class weights for loss function
                          [weight_0, weight_1, weight_2]
        """
        return self.class_weight_tensor
    
    def get_class_distribution(self):
        """
        Returns:
            dict: {label_id: count}
        """
        return self.class_counts

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        """
        Returns:
            x: torch.Tensor [feat_dim, seq_len] - TCN input format
            y: torch.Tensor [1] - label_id (0, 1, 2)
        """
        x = self.X[idx]  # [seq_len*feat_dim]
        # [seq_len, feat_dim] -> [C=feat_dim, L=seq_len] (TCN uchun)
        x = x.reshape(self.seq_len, self.feat_dim).T
        x = torch.from_numpy(x)  # float32 tensor
        y = torch.tensor(self.y[idx], dtype=torch.long)  # int64 tensor
        return x, y


# ========== EXAMPLE USAGE ==========
if __name__ == "__main__":
    import os
    
    PROJECT_ROOT = r"C:\Users\ali\Projects\fall_research"
    train_csv = os.path.join(PROJECT_ROOT, "sequences_train.csv")
    
    if os.path.exists(train_csv):
        print("[INFO] Testing SequenceCSVDataset...")
        dataset = SequenceCSVDataset(train_csv)
        
        print(f"✅ Dataset loaded: {len(dataset)} sequences")
        print(f"   seq_len: {dataset.seq_len}")
        print(f"   feat_dim: {dataset.feat_dim}")
        
        print("\n--- Class Distribution ---")
        for cls, cnt in dataset.get_class_distribution().items():
            pct = cnt / len(dataset) * 100
            print(f"  Class {cls}: {cnt:5d} ({pct:5.1f}%)")
        
        print("\n--- Class Weights (for loss) ---")
        weights = dataset.get_class_weights()
        print(f"  {weights}")
        
        print("\n--- Sample batch ---")
        x, y = dataset[0]
        print(f"  x.shape: {x.shape}  (expected: [{dataset.feat_dim}, {dataset.seq_len}])")
        print(f"  y: {y.item()} (label_id)")
        print(f"  x.dtype: {x.dtype}, y.dtype: {y.dtype}")
        
        # DataLoader test
        from torch.utils.data import DataLoader
        loader = DataLoader(dataset, batch_size=8, shuffle=True)
        batch_x, batch_y = next(iter(loader))
        print(f"\n--- DataLoader test ---")
        print(f"  batch_x.shape: {batch_x.shape}")
        print(f"  batch_y.shape: {batch_y.shape}")
        print(f"  batch_y: {batch_y.tolist()}")
    else:
        print(f"❌ {train_csv} topilmadi. Avval split_sequences.py ni ishga tushiring.")